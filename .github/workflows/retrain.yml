name: retrain-and-conditional-deploy

on:
  workflow_dispatch: {}
  schedule:
    - cron: "0 4 * * 1"   # Mondays 04:00 UTC (05:00 Zurich in winter)

env:
  IMAGE_NAME: football-api
  IMAGE_TAG: latest
  TARGET_REF: Anthony

jobs:
  retrain:
    runs-on: ubuntu-latest
    outputs:
      promote: ${{ steps.compare.outputs.promote }}
      mae_home_new: ${{ steps.metrics.outputs.mae_home }}
      mae_away_new: ${{ steps.metrics.outputs.mae_away }}

    steps:
      - name: Checkout code (Anthony branch for scheduled runs)
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: ${{ env.TARGET_REF }}

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install pipeline deps (DVC + GCS)
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install "dvc>=3.50.0" "dvc-gs>=3.0.1" "gcsfs>=2024.6.1,<2025" "fsspec>=2024.6.0,<2025"
          # runtime deps used by training/predict/metrics
          pip install pandas numpy scikit-learn

      - name: Auth to GCS for DVC (base64)
        run: |
          echo "${{ secrets.GCP_SA_KEY_B64 }}" | base64 -d > "$RUNNER_TEMP/gcp-key.json"
          echo "GOOGLE_APPLICATION_CREDENTIALS=$RUNNER_TEMP/gcp-key.json" >> "$GITHUB_ENV"

      - name: Detect DVC remote name
        id: dvcremote
        run: |
          set -e
          name="$(dvc config core.remote || true)"
          if [ -z "$name" ]; then
            # pick the first remote that points to gs://
            name="$(dvc remote list | awk '/^.+[[:space:]]+gs:\/\//{print $1; exit}')"
          fi
          if [ -z "$name" ]; then
            echo "No DVC remote found." >&2
            exit 1
          fi
          echo "Using DVC remote: $name"
          echo "remote_name=$name" >> "$GITHUB_OUTPUT"

      # Ensure DVC uses the same key file (local-only change, not committed)
      - name: Point DVC remote to the key (local-only)
        run: |
          dvc remote modify --local "${{ steps.dvcremote.outputs.remote_name }}" credentialpath "$RUNNER_TEMP/gcp-key.json"
          echo "----- .dvc/config.local -----"
          cat .dvc/config.local || true

      - name: Validate GCS credentials file
        run: |
          test -s "$RUNNER_TEMP/gcp-key.json"
          python - << 'PY'
          import os, json
          p = os.environ["GOOGLE_APPLICATION_CREDENTIALS"]
          with open(p, "r", encoding="utf-8") as f:
              data = json.load(f)
          print("Service account:", data.get("client_email"))
          PY

      - name: Show DVC remote and config
        run: |
          dvc remote list
          echo "----- .dvc/config -----"
          cat .dvc/config || true
          echo "----- .dvc/config.local -----"
          cat .dvc/config.local || true

      - name: Probe GCS access with gcsfs
        run: |
          python - << 'PY'
          import os, gcsfs
          fs = gcsfs.GCSFileSystem(token=os.environ["GOOGLE_APPLICATION_CREDENTIALS"])
          print("Bucket exists:", fs.exists("football-mlops-yah"))
          print("dvcstore exists:", fs.exists("football-mlops-yah/dvcstore"))
          PY

      - name: DVC pull (restore data & models)
        env:
          GOOGLE_APPLICATION_CREDENTIALS: ${{ runner.temp }}/gcp-key.json
        run: |
          dvc pull -v
          dvc status -c || true

      - name: Run full pipeline (fetch is frozen in dvc.yaml)
        env:
          MLFLOW_TRACKING_URI: "file:./mlruns"
        run: |
          dvc repro -f
          echo "===== DVC STATUS AFTER REPRO ====="
          dvc status -c

      - name: Push new artifacts to DVC remote
        env:
          GOOGLE_APPLICATION_CREDENTIALS: ${{ runner.temp }}/gcp-key.json
        run: dvc push -v

      - name: Compute fresh metrics from predict outputs
        id: metrics
        run: |
          python - << 'PY'
          import pandas as pd
          from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

          df = pd.read_csv("data/predictions/predicted_matches.csv")
          mae_home = mean_absolute_error(df["home_goals"], df["pred_home_goals"])
          mae_away = mean_absolute_error(df["away_goals"], df["pred_away_goals"])
          mse_home = mean_squared_error(df["home_goals"], df["pred_home_goals"])
          mse_away = mean_squared_error(df["away_goals"], df["pred_away_goals"])
          r2_home = r2_score(df["home_goals"], df["pred_home_goals"])
          r2_away = r2_score(df["away_goals"], df["pred_away_goals"])

          print("Fresh metrics:")
          print("MAE_HOME", mae_home)
          print("MAE_AWAY", mae_away)

          import os
          with open(os.environ["GITHUB_OUTPUT"], "a") as f:
              f.write(f"mae_home={mae_home}\n")
              f.write(f"mae_away={mae_away}\n")
              f.write(f"mse_home={mse_home}\n")
              f.write(f"mse_away={mse_away}\n")
              f.write(f"r2_home={r2_home}\n")
              f.write(f"r2_away={r2_away}\n")
          PY

      - name: Compare with baseline and decide promotion
        id: compare
        run: |
          python - << 'PY'
          import json, os, pathlib
          new_mae_home = float(os.environ.get("MAE_HOME", os.environ.get("mae_home", "0")))
          new_mae_away = float(os.environ.get("MAE_AWAY", os.environ.get("mae_away", "0")))
          promote = True
          baseline_path = pathlib.Path("metrics/baseline.json")
          if baseline_path.exists():
            with open(baseline_path, "r", encoding="utf-8") as f:
              base = json.load(f)
            promote = (new_mae_home <= base.get("mae_home", 1e9)) and (new_mae_away <= base.get("mae_away", 1e9))
          with open(os.environ["GITHUB_OUTPUT"], "a") as f:
            f.write(f"promote={'true' if promote else 'false'}\n")
          print("PROMOTE:", promote)
          PY
        env:
          mae_home: ${{ steps.metrics.outputs.mae_home }}
          mae_away: ${{ steps.metrics.outputs.mae_away }}

      - name: Update baseline if improved
        if: steps.compare.outputs.promote == 'true'
        run: |
          mkdir -p metrics
          python - << 'PY'
          import json, os
          data = {
            "mae_home": float(os.environ.get("MAE_HOME")),
            "mae_away": float(os.environ.get("MAE_AWAY"))
          }
          with open("metrics/baseline.json", "w", encoding="utf-8") as f:
              json.dump(data, f, indent=2)
          PY
        env:
          MAE_HOME: ${{ steps.metrics.outputs.mae_home }}
          MAE_AWAY: ${{ steps.metrics.outputs.mae_away }}

      - name: Commit & push updated dvc.lock and baseline (if any)
        if: steps.compare.outputs.promote == 'true'
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add dvc.lock metrics/baseline.json || true
          if ! git diff --cached --quiet; then
            git commit -m "chore: retrain - update lock & baseline [skip ci]"
            git push
          else
            echo "Nothing to commit."
          fi

      - name: Upload run artifacts (for inspection)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: retrain-run
          path: |
            data/processed/clean_matches.csv
            data/predictions/predicted_matches.csv
            app/model/*.json
            metrics/baseline.json
            mlruns/
          if-no-files-found: ignore

  docker:
    needs: retrain
    if: needs.retrain.outputs.promote == 'true'
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      # Ensure models exist in workspace before building the image
      - name: Set up Python for DVC pull
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install DVC + GCS (for docker job)
        run: |
          python -m pip install --upgrade pip
          pip install "dvc>=3.50.0" "dvc-gs>=3.0.1" "gcsfs>=2024.6.1,<2025" "fsspec>=2024.6.0,<2025"

      - name: Auth to GCS for DVC (base64)
        run: |
          echo "${{ secrets.GCP_SA_KEY_B64 }}" | base64 -d > "$RUNNER_TEMP/gcp-key.json"
          echo "GOOGLE_APPLICATION_CREDENTIALS=$RUNNER_TEMP/gcp-key.json" >> "$GITHUB_ENV"

      - name: Detect DVC remote name (docker job)
        id: dvcremote_docker
        run: |
          set -e
          name="$(dvc config core.remote || true)"
          if [ -z "$name" ]; then
            name="$(dvc remote list | awk '/^.+[[:space:]]+gs:\/\//{print $1; exit}')"
          fi
          if [ -z "$name" ]; then
            echo "No DVC remote found." >&2
            exit 1
          fi
          echo "Using DVC remote: $name"
          echo "remote_name=$name" >> "$GITHUB_OUTPUT"

      # Ensure DVC uses the same key file (local-only)
      - name: Point DVC remote to the key (local-only)
        run: |
          dvc remote modify --local "${{ steps.dvcremote_docker.outputs.remote_name }}" credentialpath "$RUNNER_TEMP/gcp-key.json"
          echo "----- .dvc/config.local -----"
          cat .dvc/config.local || true

      - name: Validate GCS credentials file
        run: |
          test -s "$RUNNER_TEMP/gcp-key.json"
          python - << 'PY'
          import os, json
          p = os.environ["GOOGLE_APPLICATION_CREDENTIALS"]
          with open(p, "r", encoding="utf-8") as f:
            data = json.load(f)
          print("Service account:", data.get("client_email"))
          PY

      - name: Show DVC remote and config
        run: |
          dvc remote list
          echo "----- .dvc/config -----"
          cat .dvc/config || true
          echo "----- .dvc/config.local -----"
          cat .dvc/config.local || true

      - name: Probe GCS access with gcsfs
        run: |
          python - << 'PY'
          import os, gcsfs
          fs = gcsfs.GCSFileSystem(token=os.environ["GOOGLE_APPLICATION_CREDENTIALS"])
          print("Bucket exists:", fs.exists("football-mlops-yah"))
          print("dvcstore exists:", fs.exists("football-mlops-yah/dvcstore"))
          PY

      - name: DVC pull models for image
        env:
          GOOGLE_APPLICATION_CREDENTIALS: ${{ runner.temp }}/gcp-key.json
        run: dvc pull -v

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      - name: Build and push image
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: |
            ${{ secrets.DOCKERHUB_USERNAME }}/${{ env.IMAGE_NAME }}:${{ env.IMAGE_TAG }}
            ${{ secrets.DOCKERHUB_USERNAME }}/${{ env.IMAGE_NAME }}:${{ github.sha }}
  deploy:
    needs: docker
    if: needs.retrain.outputs.promote == 'true'
    runs-on: ubuntu-latest
    environment: production
    steps:
<<<<<<< HEAD
      - uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_JSON }}   # create this secret (raw JSON)
      - uses: google-github-actions/setup-gcloud@v2
=======
      - name: Auth to GCP
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}   # âœ… use your existing RAW JSON

      - name: Setup gcloud
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}     # add this repo secret with your project id
>>>>>>> Anthony

      - name: Deploy to Cloud Run
        run: |
          gcloud run deploy football-api \
            --image=docker.io/${{ secrets.DOCKERHUB_USERNAME }}/football-api:${{ github.sha }} \
            --region=europe-west6 --platform=managed \
            --allow-unauthenticated \
            --port=8000 \
            --set-env-vars=ENV=prod \
            --max-instances=2 --cpu=1 --memory=512Mi

      - name: Show service URL
        run: gcloud run services describe football-api --region=europe-west6 --format='value(status.url)'
<<<<<<< HEAD
=======

>>>>>>> Anthony
