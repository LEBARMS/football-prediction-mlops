name: retrain-and-conditional-deploy

on:
  workflow_dispatch: {}
  schedule:
    - cron: "0 4 * * 1"   # Mondays 04:00 UTC (05:00 Zurich in winter)

env:
  IMAGE_NAME: football-api
  IMAGE_TAG: latest

jobs:
  retrain:
    runs-on: ubuntu-latest
    outputs:
      promote: ${{ steps.compare.outputs.promote }}
      mae_home_new: ${{ steps.metrics.outputs.mae_home }}
      mae_away_new: ${{ steps.metrics.outputs.mae_away }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install pipeline deps (DVC + GCS)
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install dvc dvc-gs
          # runtime deps used by training/predict/metrics
          pip install pandas numpy scikit-learn

      - name: Auth to GCS for DVC
        run: |
          echo "${{ secrets.GCP_SA_KEY }}" > $RUNNER_TEMP/gcp-key.json
          echo "GOOGLE_APPLICATION_CREDENTIALS=$RUNNER_TEMP/gcp-key.json" >> $GITHUB_ENV

      - name: Validate GCS credentials file
        run: |
          test -s "$RUNNER_TEMP/gcp-key.json"
          python - << 'PY'
          import os, json, sys
          p = os.environ["GOOGLE_APPLICATION_CREDENTIALS"]
          with open(p, "r", encoding="utf-8") as f:
              data = json.load(f)
          # print just the email to avoid leaking the full key
          print("Service account:", data.get("client_email"))
          PY

      - name: Show DVC remote and config
        run: |
          dvc remote list
          echo "----- .dvc/config -----"
          cat .dvc/config || true

      - name: Probe GCS access with gcsfs
        run: |
          python - << 'PY'
          import os, gcsfs
          fs = gcsfs.GCSFileSystem(token=os.environ["GOOGLE_APPLICATION_CREDENTIALS"])
          # list top of bucket (doesn't need listing perms beyond object admin)
          print("Bucket exists:", fs.exists("football-mlops-yah"))
          # check the dvcstore prefix existence
          print("dvcstore exists:", fs.exists("football-mlops-yah/dvcstore"))
          PY

      - name: Show DVC remotes
        run: dvc remote list

      - name: DVC pull (restore data & models)
        run: |
          dvc pull
          dvc status -c || true

      - name: Run full pipeline (fetch is frozen in dvc.yaml)
        env:
          MLFLOW_TRACKING_URI: "file:./mlruns"
        run: |
          dvc repro -f
          echo "===== DVC STATUS AFTER REPRO ====="
          dvc status -c

      - name: Push new artifacts to DVC remote
        run: dvc push

      - name: Compute fresh metrics from predict outputs
        id: metrics
        run: |
          python - << 'PY'
          import pandas as pd
          from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

          df = pd.read_csv("data/predictions/predicted_matches.csv")
          mae_home = mean_absolute_error(df["home_goals"], df["pred_home_goals"])
          mae_away = mean_absolute_error(df["away_goals"], df["pred_away_goals"])
          mse_home = mean_squared_error(df["home_goals"], df["pred_home_goals"])
          mse_away = mean_squared_error(df["away_goals"], df["pred_away_goals"])
          r2_home = r2_score(df["home_goals"], df["pred_home_goals"])
          r2_away = r2_score(df["away_goals"], df["pred_away_goals"])

          print("Fresh metrics:")
          print("MAE_HOME", mae_home)
          print("MAE_AWAY", mae_away)

          import os
          with open(os.environ["GITHUB_OUTPUT"], "a") as f:
              f.write(f"mae_home={mae_home}\n")
              f.write(f"mae_away={mae_away}\n")
              f.write(f"mse_home={mse_home}\n")
              f.write(f"mse_away={mse_away}\n")
              f.write(f"r2_home={r2_home}\n")
              f.write(f"r2_away={r2_away}\n")
          PY

      - name: Compare with baseline and decide promotion
        id: compare
        run: |
          python - << 'PY'
          import json, os, pathlib
          new_mae_home = float(os.environ.get("MAE_HOME", os.environ.get("mae_home", "0")))
          new_mae_away = float(os.environ.get("MAE_AWAY", os.environ.get("mae_away", "0")))
          promote = True
          baseline_path = pathlib.Path("metrics/baseline.json")
          if baseline_path.exists():
              with open(baseline_path, "r", encoding="utf-8") as f:
                  base = json.load(f)
              promote = (new_mae_home <= base.get("mae_home", 1e9)) and (new_mae_away <= base.get("mae_away", 1e9))
          with open(os.environ["GITHUB_OUTPUT"], "a") as f:
              f.write(f"promote={'true' if promote else 'false'}\n")
          print("PROMOTE:", promote)
          PY
        env:
          mae_home: ${{ steps.metrics.outputs.mae_home }}
          mae_away: ${{ steps.metrics.outputs.mae_away }}

      - name: Update baseline if improved
        if: steps.compare.outputs.promote == 'true'
        run: |
          mkdir -p metrics
          python - << 'PY'
          import json, os
          data = {
            "mae_home": float(os.environ.get("MAE_HOME")),
            "mae_away": float(os.environ.get("MAE_AWAY"))
          }
          with open("metrics/baseline.json", "w", encoding="utf-8") as f:
              json.dump(data, f, indent=2)
          PY
        env:
          MAE_HOME: ${{ steps.metrics.outputs.mae_home }}
          MAE_AWAY: ${{ steps.metrics.outputs.mae_away }}

      - name: Commit & push updated dvc.lock and baseline (if any)
        if: steps.compare.outputs.promote == 'true'
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add dvc.lock metrics/baseline.json || true
          if ! git diff --cached --quiet; then
            git commit -m "chore: retrain - update lock & baseline [skip ci]"
            git push
          else
            echo "Nothing to commit."
          fi

      - name: Upload run artifacts (for inspection)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: retrain-run
          path: |
            data/processed/clean_matches.csv
            data/predictions/predicted_matches.csv
            app/model/*.json
            metrics/baseline.json
            mlruns/
          if-no-files-found: ignore

  docker:
    needs: retrain
    if: needs.retrain.outputs.promote == 'true'
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      # Ensure models exist in workspace before building the image
      - name: Set up Python for DVC pull
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install DVC + GCS (for docker job)
        run: |
          python -m pip install --upgrade pip
          pip install dvc dvc-gs

      - name: Auth to GCS for DVC (docker job)
        run: |
          echo "${{ secrets.GCP_SA_KEY }}" > $RUNNER_TEMP/gcp-key.json
          echo "GOOGLE_APPLICATION_CREDENTIALS=$RUNNER_TEMP/gcp-key.json" >> $GITHUB_ENV

      - name: Validate GCS credentials file
        run: |
          test -s "$RUNNER_TEMP/gcp-key.json"
          python - << 'PY'
          import os, json, sys
          p = os.environ["GOOGLE_APPLICATION_CREDENTIALS"]
          with open(p, "r", encoding="utf-8") as f:
              data = json.load(f)
          # print just the email to avoid leaking the full key
          print("Service account:", data.get("client_email"))
          PY

      - name: Show DVC remote and config
        run: |
          dvc remote list
          echo "----- .dvc/config -----"
          cat .dvc/config || true

      - name: Probe GCS access with gcsfs
        run: |
          python - << 'PY'
          import os, gcsfs
          fs = gcsfs.GCSFileSystem(token=os.environ["GOOGLE_APPLICATION_CREDENTIALS"])
          # list top of bucket (doesn't need listing perms beyond object admin)
          print("Bucket exists:", fs.exists("football-mlops-yah"))
          # check the dvcstore prefix existence
          print("dvcstore exists:", fs.exists("football-mlops-yah/dvcstore"))
          PY
      - name: DVC pull models for image
        run: dvc pull

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      - name: Build and push image
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: |
            ${{ secrets.DOCKERHUB_USERNAME }}/${{ env.IMAGE_NAME }}:${{ env.IMAGE_TAG }}
            ${{ secrets.DOCKERHUB_USERNAME }}/${{ env.IMAGE_NAME }}:${{ github.sha }}
